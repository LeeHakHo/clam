num_updates: 200_000
# log_interval: 100
name: tssm_clam

#Hayden - Customize WanDB name
base_hp_name: AL-${env.dataset_name}_NT-${num_labelled_trajs}_SN-${seed}
hp_name: ${resolve_lapa_ckpt_name:${base_hp_name}_${env.hp_name}}


action_decoder_bs: 64
eval_every: 1000 
log_terminal_every: 1000
save_every: 50000

env:
  n_frame_stack: 1
  image_obs: True
  image_shape: [64, 64] #240/240

data:
  batch_size: 8 #128

model:
  context_len: 5 #2->32 #Hayden
  la_dim: 16
  concatenate_gripper_state: False

  slow_update_step: 100

# --- World Model Architecture Config ---
  arch:
    local_state: False
    use_pcont: True
    mem_size: 100000
    prefill: 50000
    H: 15
    q_trans: False
    patch_size: 32

    actor:
      num_units: 400
      act: "elu"
      init_std: 5.0
      dist: "onehot"
      layers: 4
      aggregator: "none"
      actor_loss_type: "both"
    value:
      num_units: 400
      act: "elu"
      dist: "normal"
      layers: 4
    world_model:
      reward_layer: 0 #4->1
      q_emb_action: False
      act_after_emb: False
      rec_sigma: 1.0
      anneal_world_model: False
      discrete_type: "discrete"
      std_type: "sigmoid2"
      temp_start: 2.0
      temp_end: 0.001
      temp_decay_steps: 1000000.0
      input_type: "image"
      train_wm_steps: 1
      transformer:
        max_time: 2000
        num_heads: 8
        d_model: 600
        d_inner: 64
        d_ff_inner: 1024
        dropout: 0.1
        dropatt: 0.1
        activation: "relu"
        pos_enc: "temporal"
        embedding_type: "linear"
        n_layers: 2
        pre_lnorm: True
        deter_type: "concat_o"
        gating: False
        last_ln: False
        enc_pos: False
        warm_up: False
      q_transformer:
        max_time: 2000
        num_heads: 8
        d_model: 600
        d_inner: 64
        d_ff_inner: 1024
        dropout: 0.1
        dropatt: 0.1
        activation: "relu"
        pos_enc: "temporal"
        embedding_type: "linear"
        n_layers: 2
        pre_lnorm: True
        deter_type: "concat_o"
        q_emb_action: False
        gating: False
        last_ln: False
      RSSM:
        act: "elu"
        weight_init: "xavier"
        stoch_size: 32
        stoch_discrete: 32
        deter_size: 600
        hidden_size: 600
        rnn_type: "LayerNormGRU"
        ST: True
        post_no_deter: False
      reward:
        num_units: 400
        act: "elu"
        dist: "normal"
        layers: 4
      pcont:
        num_units: 400
        dist: "binary"
        act: "elu"
        layers: 4
    decoder:
      dec_type: "conv"

  train:
    batch_length: 100
    batch_size: 8
    train_steps: 50
    train_every: 16
    print_every_step: 1000
    log_every_step: 1000.0
    refresh_data_every: 10000.0
    checkpoint_every_step: 50000.0
    eval_every_step: 1000.0
    test_every_step: 1000.0
    n_sample: 10
    imag_last_T: False
    log_grad: False

  loss:
    pcont_scale: 5.0
    kl_scale: 0.1
    free_nats: 0.0
    kl_balance: 0.8
    ent_scale: 0.001

  env:
    action_size: 4
    name: "atari_boxing"
    action_repeat: 4
    max_steps: 1000
    life_done: False
    precision: 32
    time_limit: 108000
    grayscale: False
    all_actions: True
    time_penalty: 0.0

  rl:
    discount: 0.999
    lambda_: 0.95
    expl_amount: 0.4
    expl_decay: 200000.0
    expl_min: 0.1
    expl_type: "epsilon_greedy"
    r_transform: "tanh"

  optimize:
    warmup_iter: 64000.0
    exp_rate: 0.5
    decay_step: 1600000.0
    base_lr: 0.0002
    end_lr: 0.0001
    model_lr: 0.0002
    value_lr: 0.0001
    actor_lr: 0.00001
    optimizer: "adamW"
    grad_clip: 100.0
    eps: 0.00001
    weight_decay: 0.000001
    reward_scale: 1.0
    discount_scale: 5.0

defaults:
  - train_clam
  - override modules/encoder: st_transformer
  - override modules/decoder: st_transformer
  - override model: st_vivit_clam
  - _self_
